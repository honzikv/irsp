{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "import os"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Adapted from TestTrecEval.java\n",
    "\n",
    "- TREC data must be converted to JSON via deserializer and placed in resources/trec\n",
    "- This notebook must be run from the root of the project"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "trec_folder = 'resources/trec'\n",
    "czech_data = os.path.join(trec_folder, 'czechData.json')\n",
    "topic_data = os.path.join(trec_folder, 'topicData.json')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load both files\n",
    "with open(czech_data, 'r', encoding='utf8') as f:\n",
    "    czech_data = json.load(f)\n",
    "\n",
    "with open(topic_data, 'r', encoding='utf8') as f:\n",
    "    topic_data = json.load(f)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\dev\\ir\\irsp\\resources/nltk/...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\dev\\ir\\irsp\\resources/nltk/...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\dev\\ir\\irsp\\resources/nltk/...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\dev\\ir\\irsp\\resources/nltk/...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file: \"czech\" to \"C:\\dev\\ir\\irsp/nltk/corpora/stopwords\"\n"
     ]
    }
   ],
   "source": [
    "# Setup NLTK\n",
    "import nltk\n",
    "from nltk_dependencies import setup_dependencies\n",
    "\n",
    "# Download dependencies\n",
    "setup_dependencies()\n",
    "\n",
    "# Configure NLTK - set the resource path to correct location\n",
    "nltk_resources_dir = os.path.join(os.getcwd(), 'resources\\\\nltk\\\\')\n",
    "nltk.data.path.append(nltk_resources_dir)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from src.preprocessing.preprocessor_configurations import czech_default_stemmer\n",
    "from src.index.index import Index\n",
    "from src.index.index_config import IndexConfig\n",
    "from src.preprocessing.preprocessing import Preprocessor\n",
    "\n",
    "# Create new index (czech since we index documents in czech)\n",
    "index = Index(\n",
    "    config=IndexConfig(\n",
    "        name='dummyIdxCs',\n",
    "        preprocessor=Preprocessor(czech_default_stemmer)\n",
    "    ),\n",
    "    initial_batch=[]\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "'81735 documents loaded'"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create domain objects\n",
    "docs = []\n",
    "for doc in czech_data:\n",
    "    docs.append(index.preprocess_document(index._parse_document_from_dict(doc)))\n",
    "\n",
    "f'{len(docs)} documents loaded'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Add documents to index\n",
    "index.add_batch(docs)\n",
    "f'{len(index.documents)} documents added to index'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from src.api.dtos import QueryDto, ModelVariant\n",
    "\n",
    "query_variants = ['title', 'description', 'both']\n",
    "\n",
    "\n",
    "def build_query_variant(topic, variant) -> str:\n",
    "    \"\"\"\n",
    "    Builds a query variant based on the topic and variant\n",
    "    :param topic:\n",
    "    :param variant:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    if variant == 'title':\n",
    "        return topic['title']\n",
    "    elif variant == 'description':\n",
    "        return topic['description']\n",
    "    elif variant == 'both':\n",
    "        return f'{topic[\"title\"]} {topic[\"description\"]}'\n",
    "    else:\n",
    "        raise ValueError(f'Unknown variant: {variant}')\n",
    "\n",
    "\n",
    "def search_topics(model_variant: ModelVariant, query_variant) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search for topics in the index using the specified model\n",
    "    :param model_variant: Model variant to use\n",
    "    :param query_variant: Query variant to use\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    # Search for topics\n",
    "    lines = []\n",
    "    for topic in topic_data:\n",
    "        # Build query object\n",
    "        topic_id = topic['id']\n",
    "        query_dto = QueryDto(\n",
    "            query=build_query_variant(topic, query_variant),\n",
    "            model=model_variant\n",
    "        )\n",
    "\n",
    "        # Search for documents\n",
    "        search_result = index.search(query_dto)\n",
    "\n",
    "        # Map to list that will be used for the script\n",
    "        # These are automatically sorted by relevance\n",
    "        documents = search_result.documents\n",
    "\n",
    "        if len(documents) == 0:\n",
    "            lines.append(f'{topic_id} Q0 abc 99 0.0 runindex1')\n",
    "            continue\n",
    "\n",
    "        for idx, document in enumerate(documents):\n",
    "            line = f'{topic_id} Q0 {document.id} {idx + 1} {document.score} runindex1'\n",
    "            lines.append(line)\n",
    "\n",
    "    return lines\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Now run search_topics for each model variant\n",
    "\n",
    "models = [\n",
    "    {'variant_name': 'TFIDF', 'model': ModelVariant.TFIDF},\n",
    "    {'variant_name': 'BOOL', 'model': ModelVariant.BOOL},\n",
    "    {'variant_name': 'BM25', 'model': ModelVariant.BM25},\n",
    "]\n",
    "\n",
    "output_path = 'trec_eval_output'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "for model in models:\n",
    "    for variant in query_variants:\n",
    "        lines = search_topics(model['variant'], variant)\n",
    "        with open(os.path.join(output_path, f'{model[\"variant_name\"]}_{variant}.txt'), 'w', encoding='utf8') as f:\n",
    "            f.write('\\n'.join(lines))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}